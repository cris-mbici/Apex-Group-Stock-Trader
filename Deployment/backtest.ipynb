{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eafa1c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_23988\\799203469.py:48: UserWarning: [19:42:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\../common/error_msg.h:82: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  model = pickle.load(f)\n",
      "c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.3.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.3.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote C:\\Users\\HP\\Desktop\\Deployment Folder\\allocations.csv\n",
      "Wrote C:\\Users\\HP\\Desktop\\Deployment Folder\\backtest_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# REQUIREMENTS:\n",
    "# pip install pandas numpy scikit-learn streamlit plotly\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------\n",
    "# Config (tweak as needed)\n",
    "# -----------------------\n",
    "FEATURES_CSV = \"step5_lagged_data.csv\"     # lagged features & label by month (t row built from t-1 features)\n",
    "PRICES_CSV   = \"prices_monthly.csv\"        # unlagged execution prices month t open/close\n",
    "MODEL_PKL    = \"ensemble_model_0p5_0p5.pkl\"\n",
    "\n",
    "START_MONTH  = \"2020-01\"                   # backtest window (inclusive)\n",
    "END_MONTH    = \"2025-10\"                   # backtest window (inclusive)\n",
    "\n",
    "# Composite weights\n",
    "PROB_W   = 0.60\n",
    "VOLUME_W = 0.30\n",
    "VOL_W    = 0.10\n",
    "\n",
    "# Filters and caps\n",
    "PROBA_MIN        = 0.50\n",
    "VOLUME_THRESHOLD = 50_000\n",
    "TOP_N            = 50\n",
    "MAX_ALLOC        = 0.20\n",
    "\n",
    "# Costs (bps, per side) â€“ override in the UI later\n",
    "FEE_BPS_PER_SIDE      = 10.0\n",
    "SLIPPAGE_BPS_PER_SIDE = 20.0\n",
    "\n",
    "# Outputs\n",
    "ALLOC_CSV    = Path(\"allocations.csv\")\n",
    "BACKTEST_CSV = Path(\"backtest_monthly.csv\")\n",
    "\n",
    "# -----------------------\n",
    "# Load data & model\n",
    "# -----------------------\n",
    "df = pd.read_csv(FEATURES_CSV, parse_dates=[\"month\"])\n",
    "df[\"month_period\"] = df[\"month\"].dt.to_period(\"M\")\n",
    "\n",
    "prices = pd.read_csv(PRICES_CSV, parse_dates=[\"month\"])\n",
    "prices[\"month_period\"] = prices[\"month\"].dt.to_period(\"M\")\n",
    "\n",
    "with open(MODEL_PKL, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Determine feature set the model expects\n",
    "if hasattr(model, \"feature_names_in_\"):\n",
    "    feat_cols = [c for c in model.feature_names_in_ if c in df.columns]\n",
    "else:\n",
    "    # Fallback: all numeric columns except the target\n",
    "    numeric = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "    feat_cols = [c for c in numeric if c != \"direction\"]\n",
    "\n",
    "# -----------------------\n",
    "# Helper: month list\n",
    "# -----------------------\n",
    "months = (\n",
    "    df[(df[\"month_period\"] >= START_MONTH) & (df[\"month_period\"] <= END_MONTH)]\n",
    "    [\"month_period\"].drop_duplicates().sort_values()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Backtest\n",
    "# -----------------------\n",
    "alloc_rows = []\n",
    "bt_rows    = []\n",
    "\n",
    "portfolio_value = 1_000_000.0\n",
    "prev_weights = {}  # ticker -> weight\n",
    "\n",
    "# For quick lookups\n",
    "px = prices.set_index([\"ticker\",\"month_period\"])[[\"open\",\"close\",\"volume\"]]\n",
    "\n",
    "for m in months:\n",
    "    df_m = df[df[\"month_period\"] == m].copy()\n",
    "    if df_m.empty:\n",
    "        continue\n",
    "\n",
    "    # Score with ensemble model\n",
    "    X = df_m[feat_cols].copy()\n",
    "    proba = model.predict_proba(X)[:, 1]\n",
    "    df_m[\"proba\"] = proba\n",
    "\n",
    "    # Vol/ATR scores (lower vol => higher score)\n",
    "    vol_med = df_m[\"vol_3m\"].median() if \"vol_3m\" in df_m.columns else 1.0\n",
    "    atr_med = df_m[\"atr_3m\"].median() if \"atr_3m\" in df_m.columns else 1.0\n",
    "    df_m[\"vol_score\"] = 1 / (1 + df_m.get(\"vol_3m\", vol_med))\n",
    "    df_m[\"atr_score\"] = 1 / (1 + df_m.get(\"atr_3m\", atr_med))\n",
    "    df_m[\"volatility_score\"] = (df_m[\"vol_score\"] + df_m[\"atr_score\"]) / 2\n",
    "\n",
    "    # Volume score normalized in-month\n",
    "    max_vol = df_m[\"volume\"].max() if \"volume\" in df_m.columns and df_m[\"volume\"].max() > 0 else 1.0\n",
    "    df_m[\"volume_score\"] = df_m.get(\"volume\", 0) / max_vol\n",
    "\n",
    "    # Composite\n",
    "    df_m[\"composite\"] = PROB_W*df_m[\"proba\"] + VOLUME_W*df_m[\"volume_score\"] + VOL_W*df_m[\"volatility_score\"]\n",
    "\n",
    "    # Filters\n",
    "    cand = df_m[df_m[\"proba\"] >= PROBA_MIN].copy()\n",
    "    if \"volume\" in cand.columns:\n",
    "        cand = cand[cand[\"volume\"] >= VOLUME_THRESHOLD]\n",
    "    if cand.empty:\n",
    "        # No positions; mark cash carry\n",
    "        bt_rows.append({\n",
    "            \"month\": str(m),\n",
    "            \"equity\": portfolio_value,\n",
    "            \"monthly_ret\": 0.0,\n",
    "            \"gross_ret\": 0.0,\n",
    "            \"net_ret\": 0.0,\n",
    "            \"turnover\": 0.0,\n",
    "            \"costs_bps_rt\": 0.0\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Rank & cap\n",
    "    cand = cand.sort_values(\"composite\", ascending=False).head(TOP_N).reset_index(drop=True)\n",
    "    cand[\"raw_w\"]   = cand[\"composite\"] / cand[\"composite\"].sum()\n",
    "    cand[\"cap_w\"]   = cand[\"raw_w\"].clip(upper=MAX_ALLOC)\n",
    "    if cand[\"cap_w\"].sum() == 0:\n",
    "        # all clipped to zero\n",
    "        bt_rows.append({\n",
    "            \"month\": str(m),\n",
    "            \"equity\": portfolio_value,\n",
    "            \"monthly_ret\": 0.0,\n",
    "            \"gross_ret\": 0.0,\n",
    "            \"net_ret\": 0.0,\n",
    "            \"turnover\": 0.0,\n",
    "            \"costs_bps_rt\": 0.0\n",
    "        })\n",
    "        continue\n",
    "    cand[\"w\"] = cand[\"cap_w\"] / cand[\"cap_w\"].sum()\n",
    "\n",
    "    # Compute turnover vs previous month\n",
    "    new_weights = dict(zip(cand[\"ticker\"], cand[\"w\"]))\n",
    "    all_tickers = set(prev_weights) | set(new_weights)\n",
    "    turnover = sum(abs(new_weights.get(t,0.0) - prev_weights.get(t,0.0)) for t in all_tickers)\n",
    "\n",
    "    # Execution: month t open -> month t close (from prices CSV)\n",
    "    rets = []\n",
    "    for _, r in cand.iterrows():\n",
    "        key = (r[\"ticker\"], m)\n",
    "        if key not in px.index:\n",
    "            # No execution prices for this name-month; treat as zero allocation\n",
    "            continue\n",
    "        o, c = px.loc[key, [\"open\",\"close\"]]\n",
    "        if o <= 0 or pd.isna(o) or pd.isna(c):\n",
    "            continue\n",
    "        gross_ret = (c - o) / o\n",
    "        rets.append(r[\"w\"] * gross_ret)\n",
    "\n",
    "        alloc_rows.append({\n",
    "            \"month\": str(m),\n",
    "            \"ticker\": r[\"ticker\"],\n",
    "            \"proba\": r[\"proba\"],\n",
    "            \"volume_score\": r[\"volume_score\"],\n",
    "            \"volatility_score\": r[\"volatility_score\"],\n",
    "            \"composite\": r[\"composite\"],\n",
    "            \"weight\": r[\"w\"],\n",
    "            \"exec_open\": float(o),\n",
    "            \"exec_close\": float(c)\n",
    "        })\n",
    "\n",
    "    gross_portfolio_ret = float(np.sum(rets)) if rets else 0.0\n",
    "\n",
    "    # Costs: round-trip bps on traded notional (turnover), per-side\n",
    "    roundtrip_bps = (FEE_BPS_PER_SIDE + SLIPPAGE_BPS_PER_SIDE) * 2.0\n",
    "    cost_fraction = (roundtrip_bps / 10_000.0) * turnover\n",
    "    net_portfolio_ret = gross_portfolio_ret - cost_fraction\n",
    "\n",
    "    # Update equity\n",
    "    portfolio_value *= (1.0 + net_portfolio_ret)\n",
    "\n",
    "    bt_rows.append({\n",
    "        \"month\": str(m),\n",
    "        \"equity\": portfolio_value,\n",
    "        \"monthly_ret\": net_portfolio_ret,\n",
    "        \"gross_ret\": gross_portfolio_ret,\n",
    "        \"net_ret\": net_portfolio_ret,\n",
    "        \"turnover\": turnover,\n",
    "        \"costs_bps_rt\": roundtrip_bps\n",
    "    })\n",
    "\n",
    "    prev_weights = new_weights\n",
    "\n",
    "# Save outputs\n",
    "pd.DataFrame(alloc_rows).to_csv(ALLOC_CSV, index=False)\n",
    "pd.DataFrame(bt_rows).to_csv(BACKTEST_CSV, index=False)\n",
    "\n",
    "print(f\"Wrote {ALLOC_CSV.resolve()}\")\n",
    "print(f\"Wrote {BACKTEST_CSV.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
