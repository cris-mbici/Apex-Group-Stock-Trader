{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "152e0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2025-10-31\"\n",
    "\n",
    "NSE = [\n",
    "    'ARM',      # ARM Cement\n",
    "    'ABSA',     # Absa Bank Kenya\n",
    "    'BAMB',     # Bamburi Cement\n",
    "    'BOC',      # B O C Kenya\n",
    "    'BRIT',     # Britam (Kenya)\n",
    "    'CARB',     # Carbacid Investments\n",
    "    'CTUM',     # Centum Investment\n",
    "    'SBIC',     # Stanbic Holdings\n",
    "    'LBTY',     # Liberty Kenya Holdings\n",
    "    'COOP',     # Co-operative Bank of Kenya\n",
    "    'CRWN',     # Crown Paints Kenya\n",
    "    'CGEN',     # Car & General (K)\n",
    "    'OCH',      # Olympia Capital Holdings\n",
    "    'DTK',      # Diamond Trust Bank Kenya\n",
    "    'EABL',     # East African Breweries\n",
    "    'CABL',     # East African Cables\n",
    "    'EGAD',     # Eaagads\n",
    "    'EQTY',     # Equity Group Holdings\n",
    "    'EVRD',     # Eveready East Africa\n",
    "    'XPRS',     # Express Kenya\n",
    "    'WTK',      # Williamson Tea Kenya\n",
    "    'HAFR',     # Home Afrika\n",
    "    'HFCK',     # HF Group\n",
    "    'IMH',      # I&M Holdings\n",
    "    'JUB',      # Jubilee Holdings\n",
    "    'KEGN',     # KenGen Company\n",
    "    'KUKZ',     # Kakuzi\n",
    "    'KQ',       # Kenya Airways\n",
    "    'KCB',      # KCB Group\n",
    "    'KNRE',     # Kenya Re-Insurance Corporation\n",
    "    'KPLC',     # Kenya Power & Lighting\n",
    "    'KAPC',     # Kapchorua Tea Kenya\n",
    "    'KURV',     # Kurwitu Ventures\n",
    "    'LKL',      # Longhorn Publishers\n",
    "    'LIMT',     # Limuru Tea\n",
    "    'MSC',      # Mumias Sugar Co\n",
    "    'NCBA',     # NCBA Group\n",
    "    'NMG',      # Nation Media Group\n",
    "    'NSE',      # Nairobi Securities Exchange\n",
    "    'SLAM',     # Sanlam Kenya\n",
    "    'SCOM',     # Safaricom\n",
    "    'SMER',     # Sameer Africa\n",
    "    'SCAN',     # WPP Scangroup\n",
    "    'SCBK',     # Standard Chartered Bank Kenya\n",
    "    'SASN',     # Sasini\n",
    "    'SGL',      # Standard Group\n",
    "    'TCL',      # TransCentury\n",
    "    'TPSE',     # TPS Eastern Africa\n",
    "    'UCHM',     # Uchumi Supermarkets\n",
    "    'UNGA',     # Unga Group\n",
    "    'TOTL',     # TotalEnergies Marketing Kenya\n",
    "    'UMME',     # Umeme\n",
    "    'FTGH',     # Flame Tree Group Holdings\n",
    "    'NBV',      # Nairobi Business Ventures\n",
    "    'DCON',     # Deacons (East Africa)\n",
    "    'BKG',      # BK Group\n",
    "    'SMWF',     # Satrix MSCI World Feeder ETF\n",
    "    'SKL',      # Shri Krishana Overseas\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28dfa653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching NSE data: 100%|██████████| 58/58 [02:42<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to start.csv (0 missing values found before cleaning)\n"
     ]
    }
   ],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "username = \"crismbici\"\n",
    "password = \"990306@CrisMbici\"\n",
    "\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "all_data = []\n",
    "nan_count = 0\n",
    "\n",
    "for symbol in tqdm(NSE, desc=\"Fetching NSE data\"):\n",
    "    try:\n",
    "        data = tv.get_hist(\n",
    "            symbol=symbol,\n",
    "            exchange=\"NSEKE\",\n",
    "            interval=Interval.in_daily,\n",
    "            n_bars=5000\n",
    "        )\n",
    "\n",
    "        if data is not None and not data.empty:\n",
    "            data = data.reset_index()\n",
    "            data[\"ticker\"] = symbol\n",
    "            nan_count += data.isna().sum().sum()\n",
    "            all_data.append(data)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "if all_data:\n",
    "    df_all = pd.concat(all_data, ignore_index=True)\n",
    "    df_all[\"datetime\"] = pd.to_datetime(df_all[\"datetime\"])\n",
    "    df_all = df_all[(df_all[\"datetime\"] >= start_date) & (df_all[\"datetime\"] <= end_date)]\n",
    "    df_all.sort_values([\"ticker\", \"datetime\"], inplace=True)\n",
    "    df_all.dropna(subset=[\"open\", \"high\", \"low\", \"close\"], inplace=True)\n",
    "    df_all.to_csv(\"start.csv\", index=False)\n",
    "    print(f\"Data saved to start.csv ({nan_count} missing values found before cleaning)\")\n",
    "else:\n",
    "    print(\"No data fetched. Check connection or symbols.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "738adbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to step2_stock_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Read daily data\n",
    "df = pd.read_csv(\"start.csv\")\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df[\"month\"] = df[\"datetime\"].dt.to_period(\"M\")\n",
    "\n",
    "# Aggregate to monthly\n",
    "monthly = (\n",
    "    df.groupby([\"ticker\", \"month\"]).agg(\n",
    "        open=(\"open\", \"first\"),\n",
    "        high=(\"high\", \"max\"),\n",
    "        low=(\"low\", \"min\"),\n",
    "        close=(\"close\", \"last\"),\n",
    "        volume=(\"volume\", \"sum\")\n",
    "    ).reset_index()\n",
    ")\n",
    "\n",
    "# Ensure month is a timestamp for sorting and merging later\n",
    "monthly[\"month\"] = monthly[\"month\"].dt.to_timestamp()\n",
    "\n",
    "# Sort for rolling calculations\n",
    "monthly = monthly.sort_values([\"ticker\", \"month\"]).reset_index(drop=True)\n",
    "\n",
    "# Feature engineering\n",
    "def compute_features(group):\n",
    "    g = group.copy()\n",
    "    g[\"return_1m\"] = g[\"close\"].pct_change()\n",
    "    g[\"log_return_1m\"] = np.log(g[\"close\"] / g[\"close\"].shift(1))\n",
    "\n",
    "    # Multi-period returns\n",
    "    for n in [3, 6, 12]:\n",
    "        g[f\"return_{n}m\"] = g[\"close\"].pct_change(n)\n",
    "        g[f\"log_return_{n}m\"] = np.log(g[\"close\"] / g[\"close\"].shift(n))\n",
    "\n",
    "    # Volatility of log returns\n",
    "    for n in [3, 6, 12]:\n",
    "        g[f\"vol_{n}m\"] = g[\"log_return_1m\"].rolling(n).std()\n",
    "\n",
    "    # True Range and ATRs\n",
    "    g[\"tr\"] = np.maximum.reduce([\n",
    "        g[\"high\"] - g[\"low\"],\n",
    "        (g[\"high\"] - g[\"close\"].shift(1)).abs(),\n",
    "        (g[\"low\"] - g[\"close\"].shift(1)).abs()\n",
    "    ])\n",
    "    g[\"atr\"] = g[\"tr\"]\n",
    "    for n in [3, 6, 12]:\n",
    "        g[f\"atr_{n}m\"] = g[\"tr\"].rolling(n).mean()\n",
    "\n",
    "    # Moving averages and ratios\n",
    "    for n in [3, 6, 12]:\n",
    "        g[f\"sma_{n}m\"] = g[\"close\"].rolling(n).mean()\n",
    "        g[f\"close_sma_ratio_{n}m\"] = g[\"close\"] / g[f\"sma_{n}m\"]\n",
    "\n",
    "    # High-low ratio\n",
    "    g[\"high_low_ratio\"] = g[\"high\"] / g[\"low\"]\n",
    "\n",
    "    # Drawdowns\n",
    "    for n in [3, 6, 12]:\n",
    "        g[f\"drawdown_{n}m\"] = (g[\"close\"] / g[\"close\"].rolling(n, min_periods=1).max()) - 1\n",
    "\n",
    "    # Rate of change\n",
    "    for n in [3, 6, 12]:\n",
    "        g[f\"roc_{n}m\"] = (g[\"close\"] - g[\"close\"].shift(n)) / g[\"close\"].shift(n)\n",
    "\n",
    "    # Positive/negative streaks\n",
    "    g[\"positive_streak\"] = (g[\"return_1m\"] > 0).astype(int).groupby((g[\"return_1m\"] <= 0).astype(int).cumsum()).cumsum()\n",
    "    g[\"negative_streak\"] = (g[\"return_1m\"] < 0).astype(int).groupby((g[\"return_1m\"] >= 0).astype(int).cumsum()).cumsum()\n",
    "\n",
    "    # Skewness and kurtosis of log returns\n",
    "    for n in [3, 6, 12]:\n",
    "        g[f\"skew_{n}m\"] = g[\"log_return_1m\"].rolling(n).apply(lambda x: skew(x, bias=False) if len(x.dropna()) > 1 else np.nan, raw=False)\n",
    "        g[f\"kurtosis_{n}m\"] = g[\"log_return_1m\"].rolling(n).apply(lambda x: kurtosis(x, bias=False) if len(x.dropna()) > 1 else np.nan, raw=False)\n",
    "\n",
    "    # Target: direction (1 if return positive, else 0)\n",
    "    g[\"direction\"] = (g[\"return_1m\"] > 0).astype(int)\n",
    "\n",
    "    return g\n",
    "\n",
    "monthly_features = monthly.groupby(\"ticker\", group_keys=False).apply(compute_features)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "monthly_features.drop(columns=[\"tr\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Save result\n",
    "monthly_features.to_csv(\"step2_stock_features.csv\", index=False)\n",
    "print(\"Saved to step2_stock_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a819e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSE_BY_SECTOR = {\n",
    "    'AGRICULTURAL': [\n",
    "        'EGAD',      # Eaagads Ltd\n",
    "        'KAPC',      # Kapchorua Tea Kenya Plc\n",
    "        'KUKZ',      # Kakuzi Plc\n",
    "        'LIMT',      # Limuru Tea Co. Ltd\n",
    "        'SASN',      # Sasini Plc\n",
    "        'WTK',       # Williamson Tea Kenya Plc\n",
    "    ],\n",
    "    \n",
    "    'AUTOMOBILES_AND_ACCESSORIES': [\n",
    "        'CGEN',      # Car & General (K) Ltd\n",
    "    ],\n",
    "    \n",
    "    'BANKING': [\n",
    "        'ABSA',      # ABSA Bank Kenya Plc\n",
    "        'SBIC',      # Stanbic Holdings Ltd\n",
    "        'IMH',       # I & M Holdings Plc\n",
    "        'DTK',       # Diamond Trust Bank Kenya Ltd\n",
    "        'HFCK',      # HF Group Plc\n",
    "        'KCB',       # KCB Group Plc\n",
    "        'NCBA',      # NCBA Group Plc\n",
    "        'SCBK',      # Standard Chartered Bank Kenya Ltd\n",
    "        'EQTY',      # Equity Group Holdings Plc\n",
    "        'COOP',      # The Co-operative Bank of Kenya Ltd\n",
    "        'BKG',       # BK Group Plc\n",
    "    ],\n",
    "    \n",
    "    'COMMERCIAL_AND_SERVICES': [\n",
    "        'XPRS',      # Express Kenya Plc\n",
    "        'KQ',        # Kenya Airways Ltd\n",
    "        'NMG',       # Nation Media Group Plc\n",
    "        'SGL',       # Standard Group Plc\n",
    "        'TPSE',      # TPS Eastern Africa (Serena) Ltd\n",
    "        'SCAN',      # WPP Scangroup Plc\n",
    "        'UCHM',      # Uchumi Supermarket Plc\n",
    "        'EVRD',      # Eveready East Africa Ltd\n",
    "        'LKL',       # Longhorn Publishers Plc\n",
    "        'DCON',      # Deacons (East Africa) Plc\n",
    "        'SMER',      # Sameer Africa Plc\n",
    "        'NBV',       # Nairobi Business Ventures Ltd\n",
    "        'HEL',       # Homeboyz Entertainment Plc (Not in your list but listed on NSE)\n",
    "    ],\n",
    "    \n",
    "    'CONSTRUCTION_AND_ALLIED': [\n",
    "        'ARM',       # ARM Cement Plc\n",
    "        'BAMB',      # Bamburi Cement Ltd\n",
    "        'CRWN',      # Crown Paints Kenya Plc\n",
    "        'CABL',      # E.A Cables Ltd (Not in your list but listed on NSE)\n",
    "        'EAPC',      # E.A Portland Cement Ltd (Not in your list but listed on NSE)\n",
    "    ],\n",
    "    \n",
    "    'ENERGY_AND_PETROLEUM': [\n",
    "        'TOTL',      # Total Kenya Ltd\n",
    "        'KEGN',      # KenGen Plc\n",
    "        'KPLC',      # Kenya Power & Lighting Plc\n",
    "        'UMME',      # Umeme Ltd\n",
    "    ],\n",
    "    \n",
    "    'INSURANCE': [\n",
    "        'JUB',       # Jubilee Holdings Ltd\n",
    "        'SLAM',      # Sanlam Kenya Plc\n",
    "        'KNRE',      # Kenya Re-Insurance Corporation Ltd\n",
    "        'LBTY',      # Liberty Kenya Holdings\n",
    "        'BRIT',      # Britam Holdings Plc\n",
    "        'CIC',       # CIC Insurance Group Ltd\n",
    "    ],\n",
    "    \n",
    "    'INVESTMENT': [\n",
    "        'OCH',       # Olympia Capital Holdings Ltd\n",
    "        'CTUM',      # Centum Investment Plc\n",
    "        'TCL',       # Trans-Century Plc\n",
    "        'HAFR',      # Home Afrika Ltd\n",
    "        'KURV',      # Kurwitu Ventures Ltd\n",
    "        'NSE',       # Nairobi Securities Exchange Plc\n",
    "    ],\n",
    "    \n",
    "    'MANUFACTURING': [\n",
    "        'BOC',       # B.O.C Kenya Plc\n",
    "        'BATK',      # British American Tobacco Kenya Plc (Not in your list but listed on NSE)\n",
    "        'CARB',      # Carbacid Investments Plc\n",
    "        'EABL',      # East African Breweries Ltd\n",
    "        'MSC',       # Mumias Sugar Co. Ltd\n",
    "        'UNGA',      # Unga Group Ltd\n",
    "        'ORCH',      # Kenya Orchards Ltd (Not in your list but listed on NSE)\n",
    "        'FTGH',      # Flame Tree Group Holdings Ltd\n",
    "        'SKL',       # Shri Krishana Overseas Plc (packaging/manufacturing)\n",
    "    ],\n",
    "    \n",
    "    'TELECOMMUNICATION': [\n",
    "        'SCOM',      # Safaricom Plc\n",
    "    ],\n",
    "    \n",
    "    'EXCHANGE_TRADED_FUNDS': [\n",
    "        'SMWF',      # Satrix MSCI World Feeder ETF\n",
    "        'GLD',       # ABSA New Gold ETF (Not in your list but listed on NSE)\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad01bef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to step3_industry_features.csv\n",
      "All tickers successfully assigned an industry.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read stock-level features\n",
    "df = pd.read_csv(\"step2_stock_features.csv\")\n",
    "df[\"month\"] = pd.to_datetime(df[\"month\"])\n",
    "\n",
    "# Build mapping from ticker to industry\n",
    "ticker_to_industry = {\n",
    "    ticker: sector\n",
    "    for sector, tickers in NSE_BY_SECTOR.items()\n",
    "    for ticker in tickers\n",
    "}\n",
    "\n",
    "# Assign industry\n",
    "df[\"industry\"] = df[\"ticker\"].map(ticker_to_industry)\n",
    "\n",
    "# Check for missing industries\n",
    "missing_tickers = df.loc[df[\"industry\"].isna(), \"ticker\"].unique().tolist()\n",
    "\n",
    "# Compute industry-level metrics\n",
    "industry_features = (\n",
    "    df.groupby([\"industry\", \"month\"]).agg(\n",
    "        industry_return_mean=(\"return_1m\", \"mean\"),\n",
    "        industry_return_median=(\"return_1m\", \"median\"),\n",
    "        industry_total_volume=(\"volume\", \"sum\"),\n",
    "        industry_avg_price=(\"close\", \"mean\"),\n",
    "        industry_volatility=(\"log_return_1m\", \"std\"),\n",
    "        industry_growth_rate=(\"return_3m\", \"mean\")\n",
    "    ).reset_index()\n",
    ")\n",
    "\n",
    "# Rolling smoothed metrics (3-month)\n",
    "industry_features = industry_features.sort_values([\"industry\", \"month\"])\n",
    "for col, new_col in [\n",
    "    (\"industry_return_mean\", \"industry_return_mean_smooth\"),\n",
    "    (\"industry_growth_rate\", \"industry_growth_rate_smooth\"),\n",
    "    (\"industry_volatility\", \"industry_volatility_smooth\")\n",
    "]:\n",
    "    industry_features[new_col] = (\n",
    "        industry_features.groupby(\"industry\")[col]\n",
    "        .transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
    "    )\n",
    "\n",
    "# Ranks within month (across industries)\n",
    "rank_cols = [\n",
    "    \"industry_return_mean\",\n",
    "    \"industry_growth_rate\",\n",
    "    \"industry_total_volume\",\n",
    "    \"industry_volatility\"\n",
    "]\n",
    "for col in rank_cols:\n",
    "    industry_features[f\"{col}_rank\"] = (\n",
    "        industry_features.groupby(\"month\")[col]\n",
    "        .rank(ascending=False, method=\"dense\")\n",
    "    )\n",
    "\n",
    "# Optional composite score\n",
    "industry_features[\"industry_score_opt\"] = (\n",
    "    0.4 * industry_features[\"industry_return_mean\"] +\n",
    "    0.3 * industry_features[\"industry_growth_rate\"] -\n",
    "    0.3 * industry_features[\"industry_volatility\"]\n",
    ")\n",
    "\n",
    "# Merge back to stock-level\n",
    "merged = df.merge(industry_features, on=[\"industry\", \"month\"], how=\"left\")\n",
    "\n",
    "# Save\n",
    "merged.to_csv(\"step3_industry_features.csv\", index=False)\n",
    "print(\"Saved to step3_industry_features.csv\")\n",
    "\n",
    "# Report missing industries\n",
    "if missing_tickers:\n",
    "    print(\"Tickers missing industry assignment:\", missing_tickers)\n",
    "else:\n",
    "    print(\"All tickers successfully assigned an industry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da41c43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to step4_macro_merged.csv\n",
      "All months matched with macro data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read files\n",
    "df = pd.read_csv(\"step3_industry_features.csv\")\n",
    "macro = pd.read_csv(\"macroeconomic.csv\")\n",
    "\n",
    "# Convert month and year\n",
    "df[\"month\"] = pd.to_datetime(df[\"month\"])\n",
    "macro[\"month\"] = pd.to_datetime(\n",
    "    macro[\"Year\"].astype(int).astype(str) + \"-\" + macro[\"Month\"].astype(int).astype(str) + \"-01\"\n",
    ")\n",
    "\n",
    "# Drop old year/month columns to avoid duplicates\n",
    "macro = macro.drop(columns=[\"Year\", \"Month\"], errors=\"ignore\")\n",
    "\n",
    "# Merge on month\n",
    "merged = df.merge(macro, on=\"month\", how=\"left\")\n",
    "\n",
    "# Save\n",
    "merged.to_csv(\"step4_macro_merged.csv\", index=False)\n",
    "print(\"Saved to step4_macro_merged.csv\")\n",
    "\n",
    "# Check if any unmatched months\n",
    "missing_months = df[\"month\"][~df[\"month\"].isin(macro[\"month\"])].unique()\n",
    "if len(missing_months):\n",
    "    print(\"Months missing macro data:\", missing_months)\n",
    "else:\n",
    "    print(\"All months matched with macro data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f38e9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values per column:\n",
      "return_12m                    17.75\n",
      "kurtosis_12m                  17.75\n",
      "skew_12m                      17.75\n",
      "roc_12m                       17.75\n",
      "atr_12m                       17.75\n",
      "vol_12m                       17.75\n",
      "log_return_12m                17.75\n",
      "sma_12m                       16.29\n",
      "close_sma_ratio_12m           16.29\n",
      "Unemployment                  14.32\n",
      "gfcf                          14.32\n",
      "return_6m                      8.99\n",
      "log_return_6m                  8.99\n",
      "kurtosis_6m                    8.99\n",
      "vol_6m                         8.99\n",
      "skew_6m                        8.99\n",
      "atr_6m                         8.99\n",
      "roc_6m                         8.99\n",
      "industry_score_opt             8.31\n",
      "sma_6m                         7.53\n",
      "close_sma_ratio_6m             7.53\n",
      "gdp_construction               5.70\n",
      "gdp_growth_rate                5.70\n",
      "gdp_manufacturing              5.70\n",
      "gdp_agriculture                5.70\n",
      "gdp_services                   5.70\n",
      "industry_volatility_rank       5.50\n",
      "industry_volatility            5.50\n",
      "industry_volatility_smooth     5.45\n",
      "skew_3m                        4.86\n",
      "kurtosis_3m                    4.86\n",
      "roc_3m                         4.58\n",
      "log_return_3m                  4.58\n",
      "vol_3m                         4.58\n",
      "return_3m                      4.58\n",
      "atr_3m                         4.58\n",
      "industry_growth_rate_smooth    4.44\n",
      "industry_growth_rate           4.44\n",
      "industry_growth_rate_rank      4.44\n",
      "supply_m2                      4.30\n",
      "close_sma_ratio_3m             3.06\n",
      "sma_3m                         3.06\n",
      "lending_rates                  2.86\n",
      "return_1m                      1.54\n",
      "atr                            1.54\n",
      "log_return_1m                  1.54\n",
      "industry_return_mean           1.46\n",
      "industry_return_median         1.46\n",
      "industry_return_mean_rank      1.46\n",
      "industry_return_mean_smooth    1.46\n",
      "interest_rates                 1.43\n",
      "gas_prices                     1.43\n",
      "industry_total_volume_rank     0.00\n",
      "ticker                         0.00\n",
      "industry_avg_price             0.00\n",
      "industry_total_volume          0.00\n",
      "industry                       0.00\n",
      "direction                      0.00\n",
      "negative_streak                0.00\n",
      "month                          0.00\n",
      "drawdown_12m                   0.00\n",
      "drawdown_6m                    0.00\n",
      "drawdown_3m                    0.00\n",
      "high_low_ratio                 0.00\n",
      "volume                         0.00\n",
      "close                          0.00\n",
      "low                            0.00\n",
      "high                           0.00\n",
      "open                           0.00\n",
      "positive_streak                0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"step4_macro_merged.csv\")\n",
    "\n",
    "# Calculate % of NaNs per column\n",
    "nan_percent = df.isna().mean() * 100\n",
    "\n",
    "# Show full output without truncation\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)  # Optional: format floats nicely\n",
    "\n",
    "print(\"Percentage of missing values per column:\")\n",
    "print(nan_percent.sort_values(ascending=False))\n",
    "\n",
    "# Reset display options to default if you want\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "594cfb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lagging features: 100%|██████████| 55/55 [00:01<00:00, 34.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagging complete with median fill. Saved as step5_lagged_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your merged data\n",
    "df = pd.read_csv(\"step4_macro_merged.csv\")\n",
    "\n",
    "# Ensure month is datetime\n",
    "df['month'] = pd.to_datetime(df['month'])\n",
    "\n",
    "# Identify columns\n",
    "id_cols = ['ticker', 'industry', 'month']\n",
    "target_col = 'direction'\n",
    "numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Remove target from numeric columns to avoid lagging it\n",
    "if target_col in numeric_cols:\n",
    "    numeric_cols.remove(target_col)\n",
    "\n",
    "# Apply lag per ticker\n",
    "df_lagged = []\n",
    "for ticker, group in tqdm(df.groupby('ticker'), desc=\"Lagging features\"):\n",
    "    group = group.sort_values('month')\n",
    "    group[numeric_cols] = group[numeric_cols].shift(1)\n",
    "    df_lagged.append(group)\n",
    "\n",
    "df_lagged = pd.concat(df_lagged, ignore_index=True)\n",
    "\n",
    "# --- Fill NaNs with training period medians (2019-2023) ---\n",
    "train_mask = (df_lagged['month'] >= start_date) & (df_lagged['month'] <= end_date) # by Nes\n",
    "medians = df_lagged.loc[train_mask, numeric_cols].median()\n",
    "\n",
    "# Fill all NaNs using these medians\n",
    "df_lagged[numeric_cols] = df_lagged[numeric_cols].fillna(medians)\n",
    "\n",
    "# Save the lagged dataset\n",
    "df_lagged.to_csv(\"step5_lagged_data.csv\", index=False)\n",
    "print(\"Lagging complete with median fill. Saved as step5_lagged_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
